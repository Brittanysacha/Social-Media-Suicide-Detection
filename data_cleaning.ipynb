{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm import tqdm\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_post_df = pd.read_csv(\"/Users/brittanyharding/LHL-Projects/SM-suicide_detection/annotated_train_df/annotated_post_df.csv\")\n",
    "nonannotated_post_df = pd.read_csv(\"/Users/brittanyharding/LHL-Projects/SM-suicide_detection/nonannotated_test_df/nonannotated_post_df.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Slang Dictionary to Best Understand MH posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_dict = {\n",
    "    \"mh\": \"mental health\",\n",
    "    \"adhd\": \"attention deficit hyperactivity disorder\",\n",
    "    \"asd\": \"autism spectrum disorder\",\n",
    "    \"bpd\": \"borderline personality disorder\",\n",
    "    \"ocd\": \"obsessive-compulsive disorder\",\n",
    "    \"ptsd\": \"post-traumatic stress disorder\",\n",
    "    \"gad\": \"generalized anxiety disorder\",\n",
    "    \"mdd\": \"major depressive disorder\",\n",
    "    \"sad\": \"social anxiety disorder or seasonal affective disorder\",\n",
    "    \"bd\": \"bipolar disorder\",\n",
    "    \"dx\": \"diagnosis\",\n",
    "    \"tx\": \"treatment\",\n",
    "    \"rx\": \"prescription\",\n",
    "    \"cbt\": \"cognitive behavioral therapy\",\n",
    "    \"dbt\": \"dialectical behavior therapy\",\n",
    "    \"emdr\": \"eye movement desensitization and reprocessing\",\n",
    "    \"act\": \"acceptance and commitment therapy\",\n",
    "    \"ssri\": \"selective serotonin reuptake inhibitor\",\n",
    "    \"snri\": \"serotonin and norepinephrine reuptake inhibitor\",\n",
    "    \"nd\": \"neurodivergent\",\n",
    "    \"nt\": \"neurotypical\",\n",
    "    \"dsm\": \"diagnostic and statistical manual of mental disorders\",\n",
    "    \"stims\": \"self-stimulatory behavior\",\n",
    "    \"stimming\": \"self-stimulatory behavior\",\n",
    "    \"tw\": \"trigger warning\",\n",
    "    \"bp\": \"bipolar\",\n",
    "    \"apd\": \"antisocial personality disorder\",\n",
    "    \"avpd\": \"avoidant personality disorder\",\n",
    "    \"did\": \"dissociative identity disorder\",\n",
    "    \"spd\": \"schizoid personality disorder or sensory processing disorder\",\n",
    "    \"ed\": \"eating disorder\",\n",
    "    \"an\": \"anorexia nervosa\",\n",
    "    \"bn\": \"bulimia nervosa\",\n",
    "    \"bed\": \"binge eating disorder\",\n",
    "    \"osfed\": \"other specified feeding or eating disorder\",\n",
    "    \"sh\": \"self harm\",\n",
    "    \"si\": \"suicidal ideation\",\n",
    "    \"iop\": \"intensive outpatient\",\n",
    "    \"ip\": \"inpatient\",\n",
    "    \"tms\": \"transcranial magnetic stimulation\",\n",
    "    \"ect\": \"electroconvulsive therapy\",\n",
    "    \"np\": \"nurse practitioner\",\n",
    "    \"pa\": \"physician's assistant\",\n",
    "    \"psyd\": \"doctor of psychology\",\n",
    "    \"md\": \"medical doctor\",\n",
    "    \"lcsw\": \"licensed clinical social worker\",\n",
    "    \"lmft\": \"licensed marriage and family therapist\",\n",
    "    \"lpcc\": \"licensed professional clinical counselor\",\n",
    "    \"erp\": \"exposure and response prevention\",\n",
    "    \"nos\": \"not otherwise specified\",\n",
    "    \"pe\": \"prolonged exposure\",\n",
    "    \"sa\": \"social anxiety\",\n",
    "    \"meds\": \"medications\",\n",
    "    \"dpdr\": \"depersonalization-derealization\",\n",
    "    \"pdoc\": \"psychiatrist\",\n",
    "    \"tdoc\": \"therapist\",\n",
    "    \"brain fog\": \"difficulty thinking clearly\",\n",
    "    \"grounding\": \"techniques used to help stay in the present moment\",\n",
    "    \"disso\": \"dissociation\",\n",
    "    \"mania\": \"manic episode\",\n",
    "    \"hypo\": \"hypomania\",\n",
    "    \"zaps\": \"brain zaps\",\n",
    "    \"med change\": \"changing medications\",\n",
    "    \"titrate\": \"gradually increase or decrease medication dose\",\n",
    "    \"psych ward\": \"psychiatric ward\",\n",
    "    \"5150\": \"involuntary psychiatric hold\",\n",
    "    \"in crisis\": \"experiencing a mental health emergency\",\n",
    "    \"meltdown\": \"emotional breakdown\",\n",
    "    \"shutdown\": \"a response to stress or overwhelm often experienced by people with autism\",\n",
    "    \"spiraling\": \"quickly worsening mental health symptoms\",\n",
    "    \"flashbacks\": \"intrusive memories of a traumatic event\",\n",
    "    \"grounding techniques\": \"methods used to bring oneself back into the present moment\",\n",
    "    \"gaslighting\": \"manipulative behavior to make someone doubt their own experiences\",\n",
    "    \"ghosting\": \"ending a relationship by suddenly and without explanation withdrawing from all communication\",\n",
    "    \"breadcrumbing\": \"the act of sending out flirtatious, but non-committal messages in order to lure a romantic partner\",\n",
    "    \"shed\": \"self-harmed\",\n",
    "    \"op\": \"original poster\",\n",
    "    \"tl;dr\": \"too long; didn't read\",\n",
    "    \"dae\": \"does anyone else\",\n",
    "    \"iirc\": \"if i remember correctly\",\n",
    "    \"ftfy\": \"fixed that for you\",\n",
    "    \"ama\": \"ask me anything\",\n",
    "    \"amaa\": \"ask me almost anything\",\n",
    "    \"iama\": \"i am a...\",\n",
    "    \"cmv\": \"change my view\",\n",
    "    \"lpt\": \"life pro tip\",\n",
    "    \"eli5\": \"explain like i'm 5\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"imho\": \"in my honest opinion\",\n",
    "    \"ymmv\": \"your mileage may vary\",\n",
    "    \"so\": \"significant other\",\n",
    "    \"ysk\": \"you should know\",\n",
    "    \"psa\": \"public service announcement\",\n",
    "    \"til\": \"today i learned\",\n",
    "    'nsfl': \"not safe for life\",\n",
    "    'nsfw': \"not safe for work\",\n",
    "    'wip': \"work in progress\",\n",
    "    'ikyky': \"if you know you know\",\n",
    "    'finna': \"getting ready to do something\",\n",
    "    'med': \"medication\",\n",
    "    'meds': \"medications\",\n",
    "    'od d': \"overdosed\",\n",
    "    'od': \"overdose\",\n",
    "    'sm': \"social media\",\n",
    "    'pci': \"post-crisis intervention\",\n",
    "    'hr': \"human resources\",\n",
    "    \"cap\": \"lie\",\n",
    "    \"no cap\": \"no lie\",\n",
    "    \"lit\": \"amazing or exciting\",\n",
    "    \"on fleek\": \"perfect or flawless\",\n",
    "    \"flex\": \"showing off or bragging\",\n",
    "    \"clout\": \"influence or popularity\",\n",
    "    \"savage\": \"fierce or ruthless\",\n",
    "    \"GOAT\": \"greatest of all time\",\n",
    "    \"bae\": \"before anyone else\",\n",
    "    \"chill\": \"calm down\",\n",
    "    \"thirsty\": \"desperate for attention\",\n",
    "    \"woke\": \"aware or knowledgeable\",\n",
    "    \"AF\": \"as fuck (emphasizing something)\",\n",
    "    \"squad\": \"group of friends\",\n",
    "    \"hater\": \"person who dislikes or criticizes others\",\n",
    "    \"flexin'\": \"showing off or boasting\",\n",
    "    \"gig\": \"job or event\",\n",
    "    \"shook\": \"surprised or shocked\",\n",
    "    \"vibe\": \"atmosphere or feeling\",\n",
    "    \"thicc\": \"curvy or voluptuous\",\n",
    "    \"salty\": \"bitter or resentful\",\n",
    "    \"basic\": \"unoriginal or mainstream\",\n",
    "    \"extra\": \"over the top or excessive\",\n",
    "    \"depressy\": \"depressed\",\n",
    "    \"grippy sock vacation\": \"psychiatric care\",\n",
    "    \"doom scrolling\": \"obsessively scrolling\",\n",
    "    \"sewerslide\": \"suicide\",\n",
    "    \"menty b\": \"mental breakdown\",\n",
    "    \"unalive\": \"die\",\n",
    "    \"i had pasta tonight\": \"having suicidal thoughts\",\n",
    "    \"i finished my shampoo and conditioner at the same time\": \"having suicidal thoughts\",\n",
    "    \"plug\": \"drug dealer\",\n",
    "    \"420\": \"marijuana\",\n",
    "    \"burnout\": \"heavy drug user\",\n",
    "    \"clucking\": \"withdrawal\",\n",
    "    \"cold turkey\": \"abrupt withdrawal\",\n",
    "    \"cooker\": \"heavy drug user\",\n",
    "    \"dial-a-doping\": \"drug delivery\",\n",
    "    \"doc\": \"drug of choice\",\n",
    "    \"faded\": \"intoxicated\",\n",
    "    \"üç≠\": \"drug user or drug supplier\",\n",
    "    \"molly\": \"mdma\",\n",
    "    \"pnp\": \"party and play\",\n",
    "    \"snowflake\": \"cocaine or overly sensitive person\",\n",
    "    \"turnt\": \"under influence\",\n",
    "    \"zombie\": \"heavy drug user\",\n",
    "    \"kys\": \"kill yourself\",\n",
    "    \"kms\": \"kill myself\",\n",
    "    \"merked\": \"very drunk or beaten up\",\n",
    "    \"#sue\": \"suicide\",\n",
    "    \"dirl\": \"die in real life\",\n",
    "    \"#ana\": \"anorexia\",\n",
    "    \"#deb\": \"depression\",\n",
    "    \"cat scratches\": \"superficial self-harm cuts\",\n",
    "    \"styros\": \"self-harm cuts to dermis\",\n",
    "    \"beans\": \"self-harm cuts to fat layer\",\n",
    "    \"x\": \"ecstasy\",\n",
    "    \"xan\": \"xanax\",\n",
    "    \"back-to-school necklace\": \"noose reference\",\n",
    "    \"#cuts\": \"self-harm discussion\",\n",
    "    \"#cu46\": \"sexual meet-up\",\n",
    "    \"#ednos\": \"unspecified eating disorder\",\n",
    "    \"#kush\": \"marijuana discussion\",\n",
    "    \"#mias\": \"bulimia discussion\",\n",
    "    \"#secretsociety123\": \"self-harm community\",\n",
    "    \"#selfharmmm\": \"self-harm discussion\",\n",
    "    \"#svv\": \"self-harm discussion\",\n",
    "    \"#tina\": \"crystal meth\",\n",
    "    \"#thinsp\": \"unhealthy weight loss promotion\",\n",
    "    \"#proana\": \"pro-anorexia promotion\",\n",
    "    \"#promia\": \"pro-bulimia promotion\",\n",
    "    \"yeet\": \"self-harm - cutting\",\n",
    "    \"yeets\": \"self-harm wounds/scars (recent)\",\n",
    "    \"yeeting\": \"cutting\",\n",
    "    \"final yeet\": \"suicide attempt\",\n",
    "    \"slicey bois\": \"razors\",\n",
    "    \"barcode\": \"cluster of self-harm wounds/scars\"\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spell checker object\n",
    "spell_checker = SpellChecker()\n",
    "\n",
    "# Add the slang terms to the spell checker's vocabulary\n",
    "spell_checker.word_frequency.load_words(slang_dict.keys())\n",
    "\n",
    "# Function to perform spell checking while preserving slang terms\n",
    "def spell_check(text):\n",
    "    # Tokenize the text into words\n",
    "    words = text.split()\n",
    "    corrected_words = []\n",
    "\n",
    "    # Iterate over the words and check if they are in the spell checker's vocabulary\n",
    "    for word in words:\n",
    "        # Check if the word is a slang term\n",
    "        if word.lower() in slang_dict:\n",
    "            corrected_word = word\n",
    "        else:\n",
    "            # Check if the word is misspelled\n",
    "            if word not in spell_checker:\n",
    "                # Get the corrected spelling for the word\n",
    "                corrected_word = spell_checker.correction(word)\n",
    "                # Handle the case where the correction is None\n",
    "                if corrected_word is None:\n",
    "                    corrected_word = word\n",
    "            else:\n",
    "                corrected_word = word\n",
    "        \n",
    "        corrected_words.append(corrected_word)\n",
    "\n",
    "    # Join the corrected words back into a string\n",
    "    corrected_text = ' '.join(corrected_words) if corrected_words else ''\n",
    "\n",
    "    return corrected_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_all(data_frame, column):\n",
    "    # Create new column names for the preprocessed text\n",
    "    new_column = 'preprocessed_' + column\n",
    "    \n",
    "    # Fill null values with empty strings\n",
    "    data_frame[column].fillna('', inplace=True)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    data_frame[new_column] = data_frame[column].apply(lambda x: x.translate(str.maketrans(\"\", \"\", string.punctuation)) if isinstance(x, str) else x)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    data_frame[new_column] = data_frame[new_column].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    data_frame[new_column] = data_frame[new_column].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]) if isinstance(x, str) else x)\n",
    "    \n",
    "    # Stem the tokens\n",
    "    stemmer = PorterStemmer()\n",
    "    data_frame[new_column] = data_frame[new_column].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]) if isinstance(x, str) else x)\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def basic_clean(data_frame, column):\n",
    "    # Create new column names for the preprocessed text\n",
    "    new_column = 'lowercase_punc_removal_' + column\n",
    "    \n",
    "    # Remove punctuation and convert to lowercase\n",
    "    data_frame[new_column] = data_frame[column].apply(lambda x: x.translate(str.maketrans(\"\", \"\", string.punctuation)).lower() if isinstance(x, str) else x)\n",
    "    \n",
    "    return data_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(data_frame, column):\n",
    "    # Create new column name for the tokenized text\n",
    "    tokenized_column = 'tokenized_' + column\n",
    "    \n",
    "    # Fill null values with empty strings\n",
    "    data_frame[column].fillna('', inplace=True)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    data_frame[tokenized_column] = data_frame[column].apply(lambda x: word_tokenize(x) if isinstance(x, str) else x)\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Annotated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the spell_check function to the 'post' column in your annotated_post_df DataFrame\n",
    "annotated_post_df['post'] = annotated_post_df['post'].apply(spell_check)\n",
    "\n",
    "# Apply the preprocess_all function to annotated_post_df\n",
    "annotated_post_df = preprocess_all(annotated_post_df, 'post')\n",
    "\n",
    "# Apply the basic_clean function to annotated_post_df\n",
    "annotated_post_df = basic_clean(annotated_post_df, 'post')\n",
    "\n",
    "# Apply the tokenize_text function to annotated_post_df\n",
    "annotated_post_df = tokenize_text(annotated_post_df, 'preprocessed_post')\n",
    "annotated_post_df = tokenize_text(annotated_post_df, 'lowercase_punc_removal_post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "annotated_post_df['sentiment_polarity'] = annotated_post_df['post'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "annotated_post_df['sentiment_subjectivity'] = annotated_post_df['post'].apply(lambda x: TextBlob(x).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotated_post_df to clean_annotated_posts.csv\n",
    "annotated_post_df.to_csv('clean_annotated_posts.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Non-Annotated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply the spell_check function to the 'post' column in your nonannotated_post_df DataFrame\n",
    "# nonannotated_post_df['post'] = nonannotated_post_df['post'].apply(spell_check)\n",
    "\n",
    "# # Apply the preprocess_all function to annotated_post_df\n",
    "# nonannotated_post_df = preprocess_all(nonannotated_post_df, 'post')\n",
    "\n",
    "# # Apply the basic_clean function to annotated_post_df\n",
    "# nonannotated_post_df = basic_clean(nonannotated_post_df, 'post')\n",
    "\n",
    "# Apply the tokenize_text function to annotated_post_df\n",
    "nonannotated_post_df = tokenize_text(nonannotated_post_df, 'preprocessed_post')\n",
    "nonannotated_post_df = tokenize_text(nonannotated_post_df, 'lowercase_punc_removal_post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotated_post_df to clean_annotated_posts.csv\n",
    "nonannotated_post_df.to_csv('clean_non_annotated_posts.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
